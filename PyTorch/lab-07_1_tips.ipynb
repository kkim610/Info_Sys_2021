{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"lab-07_1_tips.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"R2AQ-m0H9PRH"},"source":["# Lab 7-1: Tips"]},{"cell_type":"markdown","metadata":{"id":"rFefJTHs9PRO"},"source":["Author: Seungjae Lee (이승재)"]},{"cell_type":"code","metadata":{"id":"MPnZWxg9GgnX"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJ9ZisQbGgsJ"},"source":["cd drive/My Drive/class20211/PyTorch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lPQ4dpyX9PRP"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vM2lMD6W9PRP"},"source":["# For reproducibility\n","torch.manual_seed(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AOYdjC0m9PRQ"},"source":["## Training and Test Datasets"]},{"cell_type":"code","metadata":{"id":"2Z8GiIMt9PRR"},"source":["x_train = torch.FloatTensor([[1, 2, 1],\n","                             [1, 3, 2],\n","                             [1, 3, 4],\n","                             [1, 5, 5],\n","                             [1, 7, 5],\n","                             [1, 2, 5],\n","                             [1, 6, 6],\n","                             [1, 7, 7]\n","                            ])\n","y_train = torch.LongTensor([2, 2, 2, 1, 1, 1, 0, 0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NW-VMhWn9PRR"},"source":["x_test = torch.FloatTensor([[2, 1, 1], [3, 1, 2], [3, 3, 4]])\n","y_test = torch.LongTensor([2, 2, 2])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7InjmyqF9PRR"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"YWp1J8nS9PRR"},"source":["class SoftmaxClassifierModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(3, 3)\n","    def forward(self, x):\n","        return self.linear(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MihWBDI99PRS"},"source":["model = SoftmaxClassifierModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2TwWEke69PRS"},"source":["# optimizer 설정\n","optimizer = optim.SGD(model.parameters(), lr=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kdTg4TJT9PRS"},"source":["def train(model, optimizer, x_train, y_train):\n","    nb_epochs = 20\n","    for epoch in range(nb_epochs):\n","\n","        # H(x) 계산\n","        prediction = model(x_train)\n","\n","        # cost 계산\n","        cost = F.cross_entropy(prediction, y_train)\n","\n","        # cost로 H(x) 개선\n","        optimizer.zero_grad()\n","        cost.backward()\n","        optimizer.step()\n","\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_qf7Kdq9PRT"},"source":["def test(model, optimizer, x_test, y_test):\n","    prediction = model(x_test)\n","    predicted_classes = prediction.max(1)[1]\n","    correct_count = (predicted_classes == y_test).sum().item()\n","    cost = F.cross_entropy(prediction, y_test)\n","\n","    print('Accuracy: {}% Cost: {:.6f}'.format(\n","         correct_count / len(y_test) * 100, cost.item()\n","    ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TGt65fQu9PRT"},"source":["train(model, optimizer, x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4T323H-9PRT"},"source":["test(model, optimizer, x_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G7nH89Jb9PRU"},"source":["## Learning Rate"]},{"cell_type":"markdown","metadata":{"id":"MdOZg3wB9PRU"},"source":["Gradient Descent 에서의 $\\alpha$ 값"]},{"cell_type":"markdown","metadata":{"id":"s8Se0yTR9PRU"},"source":["`optimizer = optim.SGD(model.parameters(), lr=0.1)` 에서 `lr=0.1` 이다"]},{"cell_type":"markdown","metadata":{"id":"I9lWX52k9PRU"},"source":["learning rate이 너무 크면 diverge 하면서 cost 가 점점 늘어난다 (overshooting)."]},{"cell_type":"code","metadata":{"id":"Fos9IJva9PRV"},"source":["model = SoftmaxClassifierModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0TrWn1L9PRV"},"source":["optimizer = optim.SGD(model.parameters(), lr=1e5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ORez_zpo9PRV"},"source":["train(model, optimizer, x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NUFakADp9PRV"},"source":["learning rate이 너무 작으면 cost가 거의 줄어들지 않는다."]},{"cell_type":"code","metadata":{"id":"aIG1HpiJ9PRV"},"source":["model = SoftmaxClassifierModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BFU-A9a99PRW"},"source":["optimizer = optim.SGD(model.parameters(), lr=1e-10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9daGpGSY9PRW"},"source":["train(model, optimizer, x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7IIC7Dk9PRW"},"source":["적절한 숫자로 시작해 발산하면 작게, cost가 줄어들지 않으면 크게 조정하자."]},{"cell_type":"code","metadata":{"id":"wLwuASQj9PRW"},"source":["model = SoftmaxClassifierModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLcFLMBz9PRX"},"source":["optimizer = optim.SGD(model.parameters(), lr=1e-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"36IbzHxO9PRX"},"source":["train(model, optimizer, x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"trMGzKyt9PRX"},"source":["## Data Preprocessing (데이터 전처리)"]},{"cell_type":"markdown","metadata":{"id":"JpW6pTd89PRX"},"source":["데이터를 zero-center하고 normalize하자."]},{"cell_type":"code","metadata":{"id":"aPcpetXs9PRX"},"source":["x_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70]])\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XT9eSA7B9PRY"},"source":["$$ x'_j = \\frac{x_j - \\mu_j}{\\sigma_j} $$"]},{"cell_type":"markdown","metadata":{"id":"-6CyK_Pj9PRY"},"source":["여기서 $\\sigma$ 는 standard deviation, $\\mu$ 는 평균값 이다."]},{"cell_type":"code","metadata":{"id":"u7nHsx3G9PRY"},"source":["mu = x_train.mean(dim=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKob98nz9PRY"},"source":["sigma = x_train.std(dim=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MN_Zpvbm9PRY"},"source":["norm_x_train = (x_train - mu) / sigma"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y-K_N7r-9PRY"},"source":["print(norm_x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fhJ49nIo9PRZ"},"source":["Normalize와 zero center한 X로 학습해서 성능을 보자"]},{"cell_type":"code","metadata":{"id":"j_rqs11G9PRZ"},"source":["class MultivariateLinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(3, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rl2pzHua9PRZ"},"source":["model = MultivariateLinearRegressionModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SIG8V8k99PRZ"},"source":["optimizer = optim.SGD(model.parameters(), lr=1e-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-fOYHIY9PRZ"},"source":["def train(model, optimizer, x_train, y_train):\n","    nb_epochs = 20\n","    for epoch in range(nb_epochs):\n","\n","        # H(x) 계산\n","        prediction = model(x_train)\n","\n","        # cost 계산\n","        cost = F.mse_loss(prediction, y_train)\n","\n","        # cost로 H(x) 개선\n","        optimizer.zero_grad()\n","        cost.backward()\n","        optimizer.step()\n","\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKW-B-gt9PRa"},"source":["train(model, optimizer, norm_x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L30K3gD49PRa"},"source":["## Overfitting"]},{"cell_type":"markdown","metadata":{"id":"I_9QKeWt9PRa"},"source":["너무 학습 데이터에 한해 잘 학습해 테스트 데이터에 좋은 성능을 내지 못할 수도 있다."]},{"cell_type":"markdown","metadata":{"id":"dsrPf4vd9PRa"},"source":["이것을 방지하는 방법은 크게 세 가지인데:\n","\n","1. 더 많은 학습 데이터\n","2. 더 적은 양의 feature\n","3. **Regularization**"]},{"cell_type":"markdown","metadata":{"id":"mh-70pCb9PRb"},"source":["Regularization: Let's not have too big numbers in the weights"]},{"cell_type":"code","metadata":{"id":"7-QdJnS3PN0O"},"source":["a = torch.arange(3, dtype= torch.float)   \r\n","print(a)\r\n","b=torch.norm(a)   # (0**2 + 1**2 +2**2) ** (1/2)\r\n","print(b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ifIj0Cm09PRb"},"source":["def train_with_regularization(model, optimizer, x_train, y_train):\n","    nb_epochs = 20\n","    for epoch in range(nb_epochs):\n","\n","        # H(x) 계산\n","        prediction = model(x_train)\n","\n","        # cost 계산\n","        cost = F.mse_loss(prediction, y_train)\n","        \n","        # l2 norm 계산\n","        l2_reg = 0\n","        for param in model.parameters():\n","            print(\"param=\",param)\n","            print(\"torch.norm(param)\",torch.norm(param))\n","            l2_reg += torch.norm(param)\n","            \n","        cost += l2_reg\n","\n","        # cost로 H(x) 개선\n","        optimizer.zero_grad()\n","        cost.backward()\n","        optimizer.step()\n","\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch+1, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZCQhPj_U9PRb"},"source":["model = MultivariateLinearRegressionModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dfn2F03N9PRb"},"source":["optimizer = optim.SGD(model.parameters(), lr=1e-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOJGvhg_9PRc"},"source":["train_with_regularization(model, optimizer, norm_x_train, y_train)"],"execution_count":null,"outputs":[]}]}