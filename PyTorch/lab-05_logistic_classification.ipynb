{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"lab-05_logistic_classification.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Yk_qauSOeMaz"},"source":["# Lab 5: Logistic Classification"]},{"cell_type":"markdown","metadata":{"id":"nZCdNLzzeMa9"},"source":["Author: Seungjae Lee (이승재)"]},{"cell_type":"markdown","metadata":{"id":"EfV7h_i3eMa-"},"source":["<div class=\"alert alert-warning\">\n","    We use elemental PyTorch to implement linear regression here. However, in most actual applications, abstractions such as <code>nn.Module</code> or <code>nn.Linear</code> are used. You can see those implementations near the end of this notebook.\n","</div>"]},{"cell_type":"code","metadata":{"id":"Eo-3QMzYjP4_"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"50F38iaOjQTM"},"source":["cd drive/My Drive/class20211/PyTorch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ac7RQlx4eMa-"},"source":["## Reminder: Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"2ADwndxieMa_"},"source":["### Hypothesis"]},{"cell_type":"markdown","metadata":{"id":"KaQ9c_C2eMa_"},"source":["$$ H(X) = \\frac{1}{1+e^{-W^T X}} $$"]},{"cell_type":"markdown","metadata":{"id":"LReLIs8IeMa_"},"source":["### Cost"]},{"cell_type":"markdown","metadata":{"id":"t-NTaagaeMbA"},"source":["$$ cost(W) = -\\frac{1}{m} \\sum y \\log\\left(H(x)\\right) + (1-y) \\left( \\log(1-H(x) \\right) $$"]},{"cell_type":"markdown","metadata":{"id":"t4NscWz6eMbA"},"source":[" - If $y \\simeq H(x)$, cost is near 0.\n"," - If $y \\neq H(x)$, cost is high."]},{"cell_type":"markdown","metadata":{"id":"Wv6f9T-meMbA"},"source":["### Weight Update via Gradient Descent"]},{"cell_type":"markdown","metadata":{"id":"m1vja_AzeMbA"},"source":["$$ W := W - \\alpha \\frac{\\partial}{\\partial W} cost(W) $$"]},{"cell_type":"markdown","metadata":{"id":"OVZwr3E2eMbB"},"source":[" - $\\alpha$: Learning rate"]},{"cell_type":"markdown","metadata":{"id":"vAT5cFQ_eMbB"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"_X2yKekGeMbB"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J36qwy4NeMbC"},"source":["# For reproducibility\n","torch.manual_seed(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xpv-hpOVeMbD"},"source":["## Training Data"]},{"cell_type":"code","metadata":{"id":"HEaJL4CHeMbD"},"source":["x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n","y_data = [[0], [0], [0], [1], [1], [1]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4SmSoWbGeMbD"},"source":["Consider the following classification problem: given the number of hours each student spent watching the lecture and working in the code lab, predict whether the student passed or failed a course. For example, the first (index 0) student watched the lecture for 1 hour and spent 2 hours in the lab session ([1, 2]), and ended up failing the course ([0])."]},{"cell_type":"code","metadata":{"id":"WqwQ4SoVeMbD"},"source":["x_train = torch.FloatTensor(x_data)\n","y_train = torch.FloatTensor(y_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MX-fVFxQeMbD"},"source":["As always, we need these data to be in `torch.Tensor` format, so we convert them."]},{"cell_type":"code","metadata":{"id":"4PRNvf--eMbE"},"source":["print(x_train.shape)\n","print(y_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5UWs9hpEeMbE"},"source":["## Computing the Hypothesis"]},{"cell_type":"markdown","metadata":{"id":"qXzlO119eMbE"},"source":["$$ H(X) = \\frac{1}{1+e^{-W^T X}} $$"]},{"cell_type":"markdown","metadata":{"id":"XHLbH0YBeMbE"},"source":["PyTorch has a `torch.exp()` function that resembles the exponential function."]},{"cell_type":"code","metadata":{"id":"gSj6a9fQeMbE"},"source":["print('e^1 equals: ', torch.exp(torch.FloatTensor([1])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AS-p6-JLeMbF"},"source":["We can use it to compute the hypothesis function conveniently."]},{"cell_type":"code","metadata":{"id":"LMeGwNEleMbF"},"source":["W = torch.zeros((2, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8VjwGawdeMbF"},"source":["hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQCClaxKeMbF"},"source":["print(hypothesis) #W 및 b가 모두 0 이므로 모두 0.5가 된다.\n","print(hypothesis.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MJv_gIkkeMbF"},"source":["Or, we could use `torch.sigmoid()` function! This resembles the sigmoid function:"]},{"cell_type":"code","metadata":{"id":"qa8uUSineMbG"},"source":["print('1/(1+e^{-1}) equals: ', torch.sigmoid(torch.FloatTensor([1])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eYYKHZfBeMbG"},"source":["Now, the code for hypothesis function is cleaner."]},{"cell_type":"code","metadata":{"id":"yfp5MpmyeMbG"},"source":["hypothesis = torch.sigmoid(x_train.matmul(W) + b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KHed8lt0eMbG"},"source":["print(hypothesis)\n","print(hypothesis.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K66r1jQfeMbG"},"source":["## Computing the Cost Function (Low-level)"]},{"cell_type":"markdown","metadata":{"id":"hv6tip7MeMbG"},"source":["$$ cost(W) = -\\frac{1}{m} \\sum y \\log\\left(H(x)\\right) + (1-y) \\left( \\log(1-H(x) \\right) $$"]},{"cell_type":"markdown","metadata":{"id":"XBsBLsIgeMbH"},"source":["We want to measure the difference between `hypothesis` and `y_train`."]},{"cell_type":"code","metadata":{"id":"R4k2W8J1eMbH"},"source":["print(hypothesis)\n","print(y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HDhOHwpKeMbH"},"source":["For one element, the loss can be computed as follows:"]},{"cell_type":"code","metadata":{"id":"HuHu3MHreMbH"},"source":["-(y_train[0] * torch.log(hypothesis[0]) + \n","  (1 - y_train[0]) * torch.log(1 - hypothesis[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rWGK3LqieMbH"},"source":["To compute the losses for the entire batch, we can simply input the entire vector."]},{"cell_type":"code","metadata":{"id":"yDoi7VbNeMbI"},"source":["losses = -(y_train * torch.log(hypothesis) + \n","           (1 - y_train) * torch.log(1 - hypothesis))\n","print(losses)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZJZZCy3peMbI"},"source":["Then, we just `.mean()` to take the mean of these individual losses."]},{"cell_type":"code","metadata":{"id":"H87DVBTReMbI"},"source":["cost = losses.mean()\n","print(cost)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jhp_DweteMbI"},"source":["## Computing the Cost Function with `F.binary_cross_entropy`"]},{"cell_type":"markdown","metadata":{"id":"IZn66wRFeMbI"},"source":["In reality, binary classification is used so often that PyTorch has a simple function called `F.binary_cross_entropy` implemented to lighten the burden."]},{"cell_type":"code","metadata":{"id":"psD9DC1WeMbI"},"source":["F.binary_cross_entropy(hypothesis, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_7yKrjezeMbJ"},"source":["## Training with Low-level Binary Cross Entropy Loss"]},{"cell_type":"code","metadata":{"id":"BL3sisWIeMbJ"},"source":["x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n","y_data = [[0], [0], [0], [1], [1], [1]]\n","x_train = torch.FloatTensor(x_data)\n","y_train = torch.FloatTensor(y_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmsiJL2PeMbJ"},"source":["# 모델 초기화\n","W = torch.zeros((2, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr=1)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","\n","    # Cost 계산\n","    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n","    cost = -(y_train * torch.log(hypothesis) + \n","             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e9SwomOGeMbJ"},"source":["## Training with `F.binary_cross_entropy`"]},{"cell_type":"code","metadata":{"id":"zIm-630seMbJ"},"source":["# 모델 초기화\n","W = torch.zeros((2, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr=1)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","\n","    # Cost 계산\n","    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n","    cost = F.binary_cross_entropy(hypothesis, y_train)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQcqX0j1eMbK"},"source":["## Loading Real Data"]},{"cell_type":"code","metadata":{"id":"Dj7lgBONeMbK"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9HrCc5jieMbK"},"source":["xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n","x_data = xy[:, 0:-1]\n","y_data = xy[:, [-1]]\n","x_train = torch.FloatTensor(x_data)\n","y_train = torch.FloatTensor(y_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Oxgc9IWeMbK"},"source":["print(x_train[0:5])\n","print(y_train[0:5])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I_X24KPueMbK"},"source":["## Training with Real Data using low-level Binary Cross Entropy Loss"]},{"cell_type":"code","metadata":{"id":"Nws1qBw8eMbL"},"source":["# 모델 초기화\n","W = torch.zeros((8, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr=1)\n","\n","nb_epochs = 100\n","for epoch in range(nb_epochs + 1):\n","\n","    # Cost 계산\n","    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n","    cost = -(y_train * torch.log(hypothesis) + (1 - y_train) * torch.log(1 - hypothesis)).mean()\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 10번마다 로그 출력\n","    if epoch % 10 == 0:\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X5-dyA_-eMbL"},"source":["## Training with Real Data using `F.binary_cross_entropy`"]},{"cell_type":"code","metadata":{"id":"PKWktrENeMbL"},"source":["# 모델 초기화\n","W = torch.zeros((8, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr=1)\n","\n","nb_epochs = 100\n","for epoch in range(nb_epochs + 1):\n","\n","    # Cost 계산\n","    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n","    cost = F.binary_cross_entropy(hypothesis, y_train)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 10번마다 로그 출력\n","    if epoch % 10 == 0:\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u7Jumyu4eMbL"},"source":["## Checking the Accuracy our our Model"]},{"cell_type":"markdown","metadata":{"id":"r_5sznD4eMbM"},"source":["After we finish training the model, we want to check how well our model fits the training set."]},{"cell_type":"code","metadata":{"id":"r4CChj-UeMbM"},"source":["hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n","print(hypothesis[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CunXZcD2eMbM"},"source":["We can change **hypothesis** (real number from 0 to 1) to **binary predictions** (either 0 or 1) by comparing them to 0.5."]},{"cell_type":"code","metadata":{"id":"G5IKt4fdeMbM"},"source":["prediction = hypothesis >= torch.FloatTensor([0.5])\n","print(prediction[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4qwe-EABeMbN"},"source":["Then, we compare it with the correct labels `y_train`."]},{"cell_type":"code","metadata":{"id":"zsTCtGvkeMbN"},"source":["print(prediction[:5])\n","print(y_train[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbV6JhJweMbN"},"source":["correct_prediction = prediction.float() == y_train\n","print(correct_prediction[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KGW5ccwieMbN"},"source":["Finally, we can calculate the accuracy by counting the number of correct predictions and dividng by total number of predictions."]},{"cell_type":"code","metadata":{"id":"6-S7oSObeMbO"},"source":["accuracy = correct_prediction.sum().item() / len(correct_prediction)\n","print('The model has an accuracy of {:2.2f}% for the training set.'.format(accuracy * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WzH8QPcxeMbO"},"source":["## Optional: High-level Implementation with `nn.Module`"]},{"cell_type":"code","metadata":{"id":"C-rPvaRceMbO"},"source":["class BinaryClassifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(8, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        return self.sigmoid(self.linear(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OCKwb6xceMbO"},"source":["model = BinaryClassifier()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kCTxRCReMbO"},"source":["# optimizer 설정\n","optimizer = optim.SGD(model.parameters(), lr=1)\n","\n","nb_epochs = 100\n","for epoch in range(nb_epochs + 1):\n","\n","    # H(x) 계산\n","    hypothesis = model(x_train)\n","\n","    # cost 계산\n","    cost = F.binary_cross_entropy(hypothesis, y_train)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","    \n","    # 20번마다 로그 출력\n","    if epoch % 10 == 0:\n","        prediction = hypothesis >= torch.FloatTensor([0.5])\n","        correct_prediction = prediction.float() == y_train\n","        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n","        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(\n","            epoch, nb_epochs, cost.item(), accuracy * 100,\n","        ))\n"],"execution_count":null,"outputs":[]}]}