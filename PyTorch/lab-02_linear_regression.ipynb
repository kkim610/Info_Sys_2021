{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"lab-02_linear_regression.ipynb","provenance":[],"collapsed_sections":["Nn3WGiUn7YYk","zo6h0uDK7YYl","-bMqKZKn7YYm","8pIf-npW7YYn","pZjiHyS47YYp","2et6-WOU7YYq","dpsyxk-c7YYr","v73G_s4k7YYs","GQ5bUgrq7YYt","C3wqZXG27YYu"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"i4YkCI8P7YYY"},"source":["# Lab 2: Linear Regression"]},{"cell_type":"markdown","metadata":{"id":"QRPWQoWT7YYe"},"source":["Author: Seungjae Lee (이승재)"]},{"cell_type":"markdown","metadata":{"id":"D2Md1Xpd7YYf"},"source":["<div class=\"alert alert-warning\">\n","    We use elemental PyTorch to implement linear regression here. However, in most actual applications, abstractions such as <code>nn.Module</code> or <code>nn.Linear</code> are used.\n","</div>"]},{"cell_type":"code","metadata":{"id":"RgfII54n7cmk"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvwIek6v7cx-"},"source":["cd drive/My Drive/class20211/PyTorch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ODpJ4TXa7YYg"},"source":["## Theoretical Overview"]},{"cell_type":"markdown","metadata":{"id":"TgoWA2f87YYg"},"source":["$$ H(x) = Wx + b $$"]},{"cell_type":"markdown","metadata":{"id":"KhXELPE07YYg"},"source":["$$ cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2 $$"]},{"cell_type":"markdown","metadata":{"id":"33uip93d7YYg"},"source":[" - $H(x)$: 주어진 $x$ 값에 대해 예측을 어떻게 할 것인가\n"," - $cost(W, b)$: $H(x)$ 가 $y$ 를 얼마나 잘 예측했는가"]},{"cell_type":"markdown","metadata":{"id":"c8WhzGK87YYh"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"GniRv-Hj7YYh"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPoP6DtC7YYi"},"source":["# For reproducibility\n","torch.manual_seed(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RHLAGs-n7YYj"},"source":["## Data"]},{"cell_type":"markdown","metadata":{"id":"JmYN7PpS7YYj"},"source":["We will use fake data for this example."]},{"cell_type":"code","metadata":{"id":"QfHDaT0M7YYj"},"source":["x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[1], [2], [3]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gGAD9qQf7YYj"},"source":["print(x_train)\n","print(x_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S2De7HDG7YYk"},"source":["print(y_train)\n","print(y_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A1EFhVsc7YYk"},"source":["기본적으로 PyTorch는 NCHW 형태이다.<br>\r\n","In NCHW order, the image tensor would have shape (1,3,2,2). <br>\r\n","N represents the batch dimension (number of images present), <br>\r\n","C represents the number of channels, <br>\r\n","H,W represent height and width."]},{"cell_type":"markdown","metadata":{"id":"Nn3WGiUn7YYk"},"source":["## Weight Initialization"]},{"cell_type":"code","metadata":{"id":"0eHsnjm97YYk"},"source":["W = torch.zeros(1, requires_grad=True)\n","print(W)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TsjVVnyG7YYl"},"source":["b = torch.zeros(1, requires_grad=True)\n","print(b)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zo6h0uDK7YYl"},"source":["## Hypothesis"]},{"cell_type":"markdown","metadata":{"id":"GJMUDgU67YYl"},"source":["$$ H(x) = Wx + b $$"]},{"cell_type":"code","metadata":{"id":"ZyHMzpR37YYl"},"source":["hypothesis = x_train * W + b\n","print(hypothesis)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-bMqKZKn7YYm"},"source":["## Cost"]},{"cell_type":"markdown","metadata":{"id":"BPjm8uVU7YYm"},"source":["$$ cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2 $$"]},{"cell_type":"code","metadata":{"id":"NZGkTqzd7YYm"},"source":["print(hypothesis)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mB_awp_I7YYm"},"source":["print(y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_hFPUbX7YYn"},"source":["print(hypothesis - y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uiKlIWTF7YYn"},"source":["print((hypothesis - y_train) ** 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2xy8_c7G7YYn"},"source":["cost = torch.mean((hypothesis - y_train) ** 2)\n","print(cost)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8pIf-npW7YYn"},"source":["## Gradient Descent"]},{"cell_type":"code","metadata":{"id":"KumRL7tM7YYo"},"source":["optimizer = optim.SGD([W, b], lr=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JmmE2KjH7YYo"},"source":["optimizer.zero_grad()\n","cost.backward()\n","optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTMyn51A7YYo"},"source":["print(W)\n","print(b)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5BulzLqX7YYo"},"source":["Let's check if the hypothesis is now better."]},{"cell_type":"code","metadata":{"id":"BdqZ2P1M7YYo"},"source":["hypothesis = x_train * W + b\n","print(hypothesis)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZH6Xj69n7YYp"},"source":["cost = torch.mean((hypothesis - y_train) ** 2)\n","print(cost)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pZjiHyS47YYp"},"source":["## Training with Full Code"]},{"cell_type":"markdown","metadata":{"id":"1O96YtkW7YYp"},"source":["In reality, we will be training on the dataset for multiple epochs. This can be done simply with loops."]},{"cell_type":"code","metadata":{"id":"C7Ax6lS-7YYp"},"source":["# 데이터\n","x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[1], [2], [3]])\n","# 모델 초기화\n","W = torch.zeros(1, requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr=0.01)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","    \n","    # H(x) 계산\n","    hypothesis = x_train * W + b\n","    \n","    # cost 계산\n","    cost = torch.mean((hypothesis - y_train) ** 2)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, W.item(), b.item(), cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2et6-WOU7YYq"},"source":["## High-level Implementation with `nn.Module`"]},{"cell_type":"markdown","metadata":{"id":"LBETSuGW7YYq"},"source":["Remember that we had this fake data."]},{"cell_type":"code","metadata":{"id":"mHOeVCJy7YYq"},"source":["x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[1], [2], [3]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2cBezhe47YYq"},"source":["이제 linear regression 모델을 만들면 되는데, 기본적으로 PyTorch의 모든 모델은 제공되는 `nn.Module`을 inherit 해서 만들게 됩니다."]},{"cell_type":"code","metadata":{"id":"LSR5hjY87YYq"},"source":["class LinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6pi0x8UO7YYr"},"source":["모델의 `__init__`에서는 사용할 레이어들을 정의하게 됩니다. 여기서 우리는 linear regression 모델을 만들기 때문에, `nn.Linear` 를 이용할 것입니다. 그리고 `forward`에서는 이 모델이 어떻게 입력값에서 출력값을 계산하는지 알려줍니다."]},{"cell_type":"code","metadata":{"id":"E8Glpyxk7YYr"},"source":["model = LinearRegressionModel()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dpsyxk-c7YYr"},"source":["## Hypothesis"]},{"cell_type":"markdown","metadata":{"id":"Zj0myYU-7YYr"},"source":["이제 모델을 생성해서 예측값 $H(x)$를 구해보자"]},{"cell_type":"code","metadata":{"id":"q0JQ5APQ7YYs"},"source":["hypothesis = model(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWEu6nGD7YYs"},"source":["print(hypothesis)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v73G_s4k7YYs"},"source":["## Cost"]},{"cell_type":"markdown","metadata":{"id":"btWhVnPr7YYs"},"source":["이제 mean squared error (MSE) 로 cost를 구해보자. MSE 역시 PyTorch에서 기본적으로 제공한다."]},{"cell_type":"code","metadata":{"id":"NL6qxE-q7YYs"},"source":["print(hypothesis)\n","print(y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sV9b6i-J7YYt"},"source":["cost = F.mse_loss(hypothesis, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M9plFVph7YYt"},"source":["print(cost)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GQ5bUgrq7YYt"},"source":["## Gradient Descent"]},{"cell_type":"markdown","metadata":{"id":"82KiJThO7YYt"},"source":["마지막 주어진 cost를 이용해 $H(x)$ 의 $W, b$ 를 바꾸어서 cost를 줄여봅니다. 이때 PyTorch의 `torch.optim` 에 있는 `optimizer` 들 중 하나를 사용할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"B1TYBJFj7YYt"},"source":["optimizer = optim.SGD(model.parameters(), lr=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sHshVbeC7YYu"},"source":["optimizer.zero_grad()\n","cost.backward()\n","optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C3wqZXG27YYu"},"source":["## Training with Full Code"]},{"cell_type":"markdown","metadata":{"id":"6hrvFw7_7YYu"},"source":["이제 Linear Regression 코드를 이해했으니, 실제로 코드를 돌려 피팅시켜보겠습니다."]},{"cell_type":"code","metadata":{"id":"Tg5gPvTu7YYu"},"source":["# 데이터\n","x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[1], [2], [3]])\n","# 모델 초기화\n","model = LinearRegressionModel()\n","# optimizer 설정\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","    \n","    # H(x) 계산\n","    prediction = model(x_train)\n","    \n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","    \n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","    \n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        params = list(model.parameters())\n","        W = params[0].item()\n","        b = params[1].item()\n","        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, W, b, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I-Xtykj57YYu"},"source":["점점 $H(x)$ 의 $W$ 와 $b$ 를 조정해서 cost가 줄어드는 것을 볼 수 있습니다."]}]}